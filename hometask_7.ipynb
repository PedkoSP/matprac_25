{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af4754b-be04-4e9c-bc29-9a98c2110d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3458427-e397-44b2-85f7-042b470fff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset = 'train', remove = ('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase = True, stop_words = \"english\",\n",
    "                             analyzer = 'word', min_df = 5, max_df = 0.5, max_features = 2000, binary = True)\n",
    "vectorizer.fit(newsgroups_train.data[:2000])\n",
    "\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a174b8c4-f628-406e-adf2-fc967ec9afdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "iteration: 4\n",
      "iteration: 5\n",
      "iteration: 6\n",
      "iteration: 7\n",
      "iteration: 8\n",
      "iteration: 9\n",
      "iteration: 10\n",
      "iteration: 11\n",
      "iteration: 12\n",
      "iteration: 13\n",
      "iteration: 14\n",
      "iteration: 15\n",
      "iteration: 16\n",
      "iteration: 17\n",
      "iteration: 18\n",
      "iteration: 19\n",
      "iteration: 20\n",
      "iteration: 21\n",
      "iteration: 22\n",
      "iteration: 23\n",
      "iteration: 24\n",
      "iteration: 25\n",
      "iteration: 26\n",
      "iteration: 27\n",
      "iteration: 28\n",
      "iteration: 29\n",
      "iteration: 30\n",
      "iteration: 31\n",
      "iteration: 32\n",
      "iteration: 33\n",
      "iteration: 34\n",
      "iteration: 35\n",
      "iteration: 36\n",
      "iteration: 37\n",
      "iteration: 38\n",
      "iteration: 39\n",
      "iteration: 40\n",
      "iteration: 41\n",
      "iteration: 42\n",
      "iteration: 43\n",
      "iteration: 44\n",
      "iteration: 45\n",
      "iteration: 46\n",
      "iteration: 47\n",
      "iteration: 48\n",
      "iteration: 49\n",
      "iteration: 50\n",
      "iteration: 51\n",
      "iteration: 52\n",
      "iteration: 53\n",
      "iteration: 54\n",
      "iteration: 55\n",
      "iteration: 56\n",
      "iteration: 57\n",
      "iteration: 58\n",
      "iteration: 59\n",
      "iteration: 60\n",
      "iteration: 61\n",
      "iteration: 62\n",
      "iteration: 63\n",
      "iteration: 64\n",
      "iteration: 65\n",
      "iteration: 66\n",
      "iteration: 67\n",
      "iteration: 68\n",
      "iteration: 69\n",
      "iteration: 70\n",
      "iteration: 71\n",
      "iteration: 72\n",
      "iteration: 73\n",
      "iteration: 74\n",
      "iteration: 75\n",
      "iteration: 76\n",
      "iteration: 77\n",
      "iteration: 78\n",
      "iteration: 79\n",
      "iteration: 80\n",
      "iteration: 81\n",
      "iteration: 82\n",
      "iteration: 83\n",
      "iteration: 84\n",
      "iteration: 85\n",
      "iteration: 86\n",
      "iteration: 87\n",
      "iteration: 88\n",
      "iteration: 89\n",
      "iteration: 90\n",
      "iteration: 91\n",
      "iteration: 92\n",
      "iteration: 93\n",
      "iteration: 94\n",
      "iteration: 95\n",
      "iteration: 96\n",
      "iteration: 97\n",
      "iteration: 98\n",
      "iteration: 99\n",
      "iteration: 100\n",
      "\n",
      "Top 10 words in each theme:\n",
      "['state' 'history' 'states' 'times' 'continue' 'world' 'today' 'away'\n",
      " 'government' 'people']\n",
      "['probably' 'unless' 'maybe' 'money' 'did' 'doesn' 'used' 'really' 'don'\n",
      " 'know']\n",
      "['just' 'isn' 'like' 'right' 'question' 'actually' 'people' 'don' 'years'\n",
      " 'think']\n",
      "['possible' 'heard' 'better' 'life' 'really' 'new' 'time' 'people' 'way'\n",
      " 'don']\n",
      "['supposed' 'skepticism' 'chastity' 'called' 'soon' 'low' 'banks' 've'\n",
      " 'like' 'edu']\n",
      "['11' '17' '14' '50' '15' '12' '25' '30' '20' '10']\n",
      "['fact' 'mean' 'things' 'way' 'right' 'does' 'believe' 'people' 'god'\n",
      " 'say']\n",
      "['want' 'didn' 'make' 'way' 'better' 'yes' 'good' 'little' 'know' 'think']\n",
      "['work' 'did' 'long' 'just' 'll' 'use' 'like' 'good' 'don' 'know']\n",
      "['lot' 'couple' 'mean' 'does' 'way' 'going' 'good' 'right' 'know' 'just']\n",
      "['address' 'following' 'edu' 'having' '1993' 'number' 'control' 'non'\n",
      " 'information' 'program']\n",
      "['talking' 'case' 'said' 'sure' 'want' 'use' 'time' 'got' 'think' 'make']\n",
      "['got' 'uses' 'great' 'thing' 'info' 'did' 'world' 'just' 'like' 'does']\n",
      "['think' 'question' 'new' 'people' 'good' 'sure' 'did' 'want' 'just' 'don']\n",
      "['make' 'good' 'point' 'quite' 'way' 'com' 'don' 'said' 'case' 'like']\n",
      "['ve' 'problem' 'card' 'pc' 'using' 'need' 'help' 'windows' 'use' 'thanks']\n",
      "['thing' 'just' 'know' 'new' 'look' 'way' 'want' 've' 'like' 'time']\n",
      "['thought' 'case' 'want' 'make' 'good' 'don' 'like' 'just' 'use' 'think']\n",
      "['people' 'let' 'll' 'know' 'days' 'try' 'used' 'didn' 'time' 'just']\n",
      "['second' 'don' 'believe' 'used' 'like' 'way' 'new' 'think' 'people'\n",
      " 'know']\n"
     ]
    }
   ],
   "source": [
    "def Sample(n, p):\n",
    "    q = p / p.sum()\n",
    "    u = np.random.rand()\n",
    "    for i in range(n):\n",
    "        if u < q[i]:\n",
    "            return i\n",
    "        else:\n",
    "            u -= q[i]\n",
    "\n",
    "def LDA_alg(K, a, N, b, W, w, D, d, iters):\n",
    "    b_sum = b.sum()\n",
    "    \n",
    "    nkw = np.zeros(K * N).reshape(K, N)\n",
    "    ndk = np.zeros(K * D).reshape(D, K)\n",
    "    nk  = np.zeros(K)\n",
    "    \n",
    "    t = np.random.dirichlet(a)\n",
    "    z = [Sample(K, t) for _ in range(W)]\n",
    "    \n",
    "    for i in range(W):\n",
    "        nkw[z[i], w[i]] += 1\n",
    "        ndk[d[i], z[i]] += 1\n",
    "        nk[z[i]]        += 1\n",
    "\n",
    "    for it in range(iters):\n",
    "        print('iteration: ' + str(it + 1))\n",
    "        \n",
    "        for i in range(W):\n",
    "            nkw[z[i], w[i]] -= 1\n",
    "            ndk[d[i], z[i]] -= 1\n",
    "            nk[z[i]]        -= 1\n",
    "\n",
    "            p = []\n",
    "            for k in range(K):\n",
    "                p.append((ndk[d[i], k] + a[k]) * (nkw[k, w[i]] + b[w[i]]) / (nk[k] + b_sum))\n",
    "\n",
    "            z[i] = Sample(len(p), np.array(p))\n",
    "            \n",
    "            nkw[z[i], w[i]] += 1\n",
    "            ndk[d[i], z[i]] += 1\n",
    "            nk[z[i]]        += 1\n",
    "\n",
    "    return z\n",
    "\n",
    "K = 20\n",
    "a = np.ones(K)\n",
    "\n",
    "N = len(vectorizer.vocabulary_)\n",
    "b = np.ones(N)\n",
    "\n",
    "w = X_train.nonzero()[1]\n",
    "W = len(w)\n",
    "\n",
    "d = X_train.nonzero()[0]\n",
    "D = X_train.shape[0]\n",
    "\n",
    "iters = 100\n",
    "\n",
    "z = LDA_alg(K, a, N, b, W, w, D, d, iters)\n",
    "\n",
    "nkw = np.zeros(K * N).reshape(K, N)\n",
    "\n",
    "for i in range(W):\n",
    "    nkw[z[i], w[i]] += 1\n",
    "\n",
    "print('\\nTop 10 words in each theme:')\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for k in range(K):\n",
    "    arr = np.argpartition(nkw[k], -10)[-10:]\n",
    "    print(words[arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747d892-f764-42e1-a727-0f4f3da15f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
